{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px; margin-bottom: 10px; border: 1px solid #333333;\">\n",
    "    \n",
    "# support mission   \n",
    "    \n",
    "### このsupport mission では、先ほど作成したmodelに基づき、カメラに映っている状況がfreeである確率とblockedである確率を返してくれる事を確認する\n",
    "\n",
    "## <span style=\"color: red; \">NEW</span> カテゴリ：[モデルによる判定結果にもとづくロボットカーの制御]\n",
    "\n",
    "## 完了の定義：jetbotの前に赤いレゴブロックで作られた壁が存在する場合、jetbotが停止し、そうでない場合は直進すること\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックでは、トレーニングしたモデルを使用して、jetbotの衝突回避動作を有効にするために、jetbotがfreeであるかblockedな状況かを検出します。 \n",
    "\n",
    "## 訓練されたモデルを読み込もう\n",
    "\n",
    "トレーニングノートの指示に従って、best_model.pthをこのファイルと同じディレクトリに置いていることを前提としています。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# 学習済みモデルを初期化しています\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に ``best_model.pth`` ファイルを読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在、モデルはCPUメモリにあり、以下のコードを実行してGPUデバイスに転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理を行う関数を定義する\n",
    "モデルを読み込みましたが、少し問題があります。 モデルをトレーニングした形式は、カメラの形式と完全には一致しません。 そのためには、いくつかの前処理を行う必要があり以下の手順をふむ必要があります\n",
    "\n",
    "1. BGRからRGBに変換する\n",
    "2. HWCレイアウトからCHWレイアウトに変換する\n",
    "3. トレーニング中に行ったのと同じパラメーターを使用して正規化します（カメラは[0、255]の範囲の値を提供し、ロードされた画像は[0、1]の範囲でトレーニングします。したがって、255.0\n",
    "4. CPUメモリからGPUメモリにデータを転送します\n",
    "5. バッチディメンションを追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "# カメラからの画像を正規化するメソッドを定義しています\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、カメラの形式からニューラルネットワークの入力形式に画像を変換できる前処理関数を定義しました。\n",
    "\n",
    "それでは、カメラを起動して表示しましょう。 \n",
    "jetbotがblockedであると判断する確率を表示するスライダーを作成します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "# blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# display(widgets.HBox([image, blocked_slider]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、カメラの値が変更されるたびに呼び出される関数を作成します。 この関数は次の手順を実行します\n",
    "\n",
    "1. カメラ画像の前処理\n",
    "2. ニューラルネットワークを実行する\n",
    "3. 出力に応じて動作を変更する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px; margin-bottom: 10px; border: 1px solid #333333;\">\n",
    "\n",
    "\n",
    "## <span style=\"color: red; \">NEW</span> カテゴリ：[モデルによる判定結果にもとづくロボットカーの制御]\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-5ec97c371413>\", line 16, in <module>\n",
      "    update({'new': camera.value})  # we call the function once to intialize\n",
      "NameError: name 'camera' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1488, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1446, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'camera' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def update(change):\n",
    "    global blocked_slider, robot\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    ## 削除した部分を下記のようにロボットを制御するためのプログラムに変更しました\n",
    "    if prob_blocked < 0.5:\n",
    "        robot.forward(0.4)\n",
    "    else:\n",
    "        robot.left(0.4)\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "    ####################################################################\n",
    "update({'new': camera.value})  # we call the function once to intialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.link()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
