{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision Avoidance - Live Demo\n",
    "\n",
    "In this notebook we'll use the model we trained to detect whether the robot is ``free`` or ``blocked`` to enable a collision avoidance behavior on the robot.  \n",
    "\n",
    "## Load the trained model\n",
    "\n",
    "We'll assumed that you've already downloaded the ``best_model.pth`` to your workstation as instructed in the training notebook.  Now, you should upload this model into this notebook's\n",
    "directory by using the Jupyter Lab upload tool.  Once that's finished there should be a file named ``best_model.pth`` in this notebook's directory.  \n",
    "\n",
    "> Please make sure the file has uploaded fully before calling the next cell\n",
    "\n",
    "Execute the code below to initialize the PyTorch model.  This should look very familiar from the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the trained weights from the ``best_model.pth`` file that you uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the model weights are located on the CPU memory execute the code below to transfer to the GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the preprocessing function\n",
    "\n",
    "We have now loaded our model, but there's a slight issue.  The format that we trained our model doesnt *exactly* match the format of the camera.  To do that, \n",
    "we need to do some *preprocessing*.  This involves the following steps\n",
    "\n",
    "1. Convert from BGR to RGB\n",
    "2. Convert from HWC layout to CHW layout\n",
    "3. Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "4. Transfer the data from CPU memory to GPU memory\n",
    "5. Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We've now defined our pre-processing function which can convert images from the camera format to the neural network input format.\n",
    "\n",
    "Now, let's start and display our camera.  You should be pretty familiar with this by now.  We'll also create a slider that will display the\n",
    "probability that the robot is blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ee70ac5bf245f29c0e5b6443ca37fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00Câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image, blocked_slider]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create our robot instance which we'll need to drive the motors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a function that will get called whenever the camera's value changes.  This function will do the following steps\n",
    "\n",
    "1. Pre-process the camera image\n",
    "2. Execute the neural network\n",
    "3. While the neural network output indicates we're blocked, we'll turn left, otherwise we go forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5285e-05, 9.9998e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "def update(change):\n",
    "    global blocked_slider, robot\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    time.sleep(1)\n",
    "    print(y)\n",
    "    \n",
    "#     prob_blocked = float(y.flatten()[0])\n",
    "    \n",
    "#     blocked_slider.value = prob_blocked\n",
    "    \n",
    "#     if prob_blocked < 0.5:\n",
    "#         robot.forward(0.4)\n",
    "#     else:\n",
    "#         robot.left(0.4)\n",
    "    \n",
    "#     time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to intialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We've created our neural network execution function, but now we need to attach it to the camera for processing. \n",
    "\n",
    "We accomplish that with the ``observe`` function.\n",
    "\n",
    "> WARNING: This code will move the robot!! Please make sure your robot has clearance.  The collision avoidance should work, but the neural\n",
    "> network is only as good as the data it's trained on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.9835e-05, 9.9997e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6747e-04, 9.9983e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0021, 0.9979]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.4587e-04, 9.9925e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.8140e-04, 9.9962e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0064, 0.9936]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.0499e-04, 9.9980e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.7329e-04, 9.9913e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.8641e-05, 9.9995e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.4049e-04, 9.9906e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7950e-04, 9.9982e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6320e-04, 9.9984e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6949e-06, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0057, 0.9943]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.2824e-05, 9.9995e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0041, 0.9959]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0031, 0.9969]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1251e-04, 9.9969e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7341e-06, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.2059e-08, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5090e-06, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.6426e-06, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.5756e-06, 9.9999e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.9789e-04, 9.9930e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9466e-05, 9.9998e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.8052e-04, 9.9902e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.9570e-06, 9.9999e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5454e-05, 9.9998e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4532e-04, 9.9985e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.2747e-04, 9.9947e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.2340e-05, 9.9997e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.3489e-06, 9.9999e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1114e-06, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.3270e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.8001e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 5.6649e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.9200e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9973e-01, 2.7350e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7696, 0.2304]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2767e-04, 9.9977e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6752e-05, 9.9998e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.1212e-06, 9.9999e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7088e-04, 9.9983e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2192e-05, 9.9999e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6957e-05, 9.9998e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.8888e-06, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.3809e-06, 9.9999e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.3868e-05, 9.9994e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3835e-04, 9.9986e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.4383e-07, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.4120e-05, 9.9992e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8578e-04, 9.9981e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.8084e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 6.5044e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.2547e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.4793e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.8556e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.8267e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.9078e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5466e-04, 9.9985e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0011, 0.9989]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7596e-05, 9.9997e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0521, 0.9479]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1857e-04, 9.9988e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1801e-04, 9.9978e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.6349e-05, 9.9995e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0337, 0.9663]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0556, 0.9444]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9940e-01, 5.9879e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 6.3046e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9969e-01, 3.1452e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9953e-01, 4.6635e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 6.7457e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 4.1923e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9989, 0.0011]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 5.0008e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9978, 0.0022]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 6.3697e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 3.7998e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 6.8195e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.7349e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.8541e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.9267e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 3.9865e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 5.9908e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.8301e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 6.7043e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.7761e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 6.4524e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9953e-01, 4.7340e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 6.2488e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 4.3220e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9984e-01, 1.6414e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.1935e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9985e-01, 1.4627e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.1097e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 5.3641e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.3953e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9985e-01, 1.4657e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9965e-01, 3.4938e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 4.0958e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9966e-01, 3.3700e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.7184e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.2468e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.8869e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9986e-01, 1.4141e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9962e-01, 3.8173e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 4.5130e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 3.5905e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9907e-01, 9.3480e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 7.4628e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9966e-01, 3.3544e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9952, 0.0048]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.4071e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.4181e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 4.9364e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9947e-01, 5.3217e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.1976e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.6110e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9970, 0.0030]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9990e-01, 1.0335e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9973e-01, 2.7373e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9947e-01, 5.2615e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9911e-01, 8.8610e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9962e-01, 3.8453e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 5.5729e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.4474e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.1092e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.9045e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9925e-01, 7.5416e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 3.5727e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.7581e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.3636e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.6903e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 6.2793e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 6.6297e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9980e-01, 1.9828e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9954e-01, 4.6157e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9989e-01, 1.1255e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 5.3705e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 7.3466e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9920e-01, 7.9518e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.4066e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 9.7726e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.4390e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.2328e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 6.6236e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9992e-01, 8.2125e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.8054e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 3.1041e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9988e-01, 1.2354e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.2623e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 5.7192e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 5.1065e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 7.1605e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.3820e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9969e-01, 3.1456e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.1510e-08]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.4145e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9990e-01, 1.0432e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 8.4008e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 5.5226e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9905, 0.0095]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 5.2799e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9983e-01, 1.7315e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9913, 0.0087]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.2267e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9988e-01, 1.1898e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9005, 0.0995]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9968e-01, 3.2056e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9965, 0.0035]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9943e-01, 5.6790e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9975e-01, 2.5428e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.5840e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9979, 0.0021]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9971, 0.0029]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9977, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9974e-01, 2.6257e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.2258e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9971e-01, 2.8569e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9920e-01, 7.9910e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.4774e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9980e-01, 1.9680e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 3.8845e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.7607e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.0340e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 5.5664e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.9408e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.1226e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9654, 0.0346]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9731, 0.0269]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9943, 0.0057]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9976, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9974, 0.0026]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.9625e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9975e-01, 2.5001e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9947, 0.0053]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9992e-01, 7.9244e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9965e-01, 3.4986e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9988e-01, 1.2129e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.3811e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9982e-01, 1.7623e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9969e-01, 3.0677e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9941e-01, 5.8549e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 6.5687e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.8137e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9909e-01, 9.0846e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9907e-01, 9.2527e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9024, 0.0976]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.1318e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9957, 0.0043]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9980e-01, 2.0490e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9981e-01, 1.8525e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9956, 0.0044]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9979, 0.0021]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.8435e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9982e-01, 1.7712e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.4041e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9976e-01, 2.3781e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9950e-01, 5.0443e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9957e-01, 4.3255e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9946e-01, 5.3892e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 7.0542e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9921, 0.0079]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9954e-01, 4.6292e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9989, 0.0011]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9915e-01, 8.5391e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9992e-01, 7.6001e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9987e-01, 1.2905e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9978e-01, 2.1775e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9949e-01, 5.1115e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9971e-01, 2.9501e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9988e-01, 1.2485e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9918e-01, 8.1974e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 4.6352e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9991e-01, 9.3598e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9990e-01, 9.9010e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9903e-01, 9.7409e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9955e-01, 4.5220e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9984e-01, 1.6406e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 6.2226e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9988e-01, 1.1602e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 3.7806e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9884, 0.0116]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9966e-01, 3.4029e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9992e-01, 8.3929e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9971e-01, 2.8987e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9960, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 6.4599e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9934, 0.0066]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.2903e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9981e-01, 1.8749e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.0599e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9978e-01, 2.1595e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9980e-01, 2.0030e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 4.8507e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9975e-01, 2.4779e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9982e-01, 1.8318e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9971e-01, 2.8896e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9979, 0.0021]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9991e-01, 8.7141e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9964e-01, 3.6282e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.4172e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9983e-01, 1.6614e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.6581e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9984e-01, 1.6283e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9932e-01, 6.8175e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.6708e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9986e-01, 1.4154e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 7.2986e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.3937e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.0090e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.4505e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 3.8631e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 9.0491e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 4.0254e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9905e-01, 9.4768e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 5.1031e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9992e-01, 8.0750e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.0009e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9901, 0.0099]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9957e-01, 4.2790e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 7.3934e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9928e-01, 7.2353e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9986e-01, 1.3771e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9967e-01, 3.3463e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9991e-01, 9.0393e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9984e-01, 1.5911e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9932e-01, 6.8158e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9943, 0.0057]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9976e-01, 2.3835e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9925, 0.0075]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9976, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9655, 0.0345]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9956e-01, 4.4180e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9986e-01, 1.3939e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.2109e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9900e-01, 9.9587e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9964e-01, 3.6238e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9990e-01, 9.8476e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9990e-01, 9.5291e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9948e-01, 5.1893e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.7749e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9978e-01, 2.2466e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9990, 0.0010]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.6375e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9976e-01, 2.4123e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9958e-01, 4.2085e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 6.4056e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 5.2313e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9988e-01, 1.2497e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9980e-01, 1.9665e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 6.6949e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9973e-01, 2.6738e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 8.9548e-07]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 3.1134e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9989e-01, 1.0761e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 9.5379e-07]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9906e-01, 9.3731e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9982e-01, 1.8224e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.1790e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.3352e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9971e-01, 2.8692e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9987e-01, 1.3065e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9984e-01, 1.5788e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 5.8619e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.7236e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.3645e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 5.3717e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9972e-01, 2.7999e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9990e-01, 1.0245e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.9916e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 7.0586e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9906e-01, 9.4137e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 5.6530e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9991e-01, 9.0436e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.2056e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9931e-01, 6.8957e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.5154e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9987e-01, 1.3245e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9928e-01, 7.2183e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9975e-01, 2.5187e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9959e-01, 4.0706e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.4437e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 6.3422e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9934e-01, 6.6299e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 4.7863e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.2276e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9935e-01, 6.5018e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.6024e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 4.4191e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9964e-01, 3.5790e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9981e-01, 1.9485e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 5.5248e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9984e-01, 1.6284e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9991e-01, 9.0497e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 3.1602e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9848, 0.0152]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9969, 0.0031]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.1485e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9990e-01, 9.7495e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9968e-01, 3.1860e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9980e-01, 1.9669e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9937e-01, 6.3425e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9957e-01, 4.2689e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 7.3789e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9901e-01, 9.8803e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9984e-01, 1.5770e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9987e-01, 1.3406e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9958, 0.0042]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.5240e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9930e-01, 6.9752e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 6.8401e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 1.6826e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 5.7654e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9906e-01, 9.3591e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9580, 0.0420]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9974, 0.0026]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9942e-01, 5.8061e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9976, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9979, 0.0021]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9984e-01, 1.5880e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.9791e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9992e-01, 7.5671e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9989e-01, 1.0802e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9966e-01, 3.4210e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9930e-01, 7.0379e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9981e-01, 1.9484e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.6981e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9967e-01, 3.3328e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 4.6724e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9962e-01, 3.7706e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 7.2799e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9947e-01, 5.3116e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9962e-01, 3.8139e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 8.1884e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.3317e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 5.7923e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9939e-01, 6.1265e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 4.1486e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.3253e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.9126e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9956, 0.0044]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9990e-01, 1.0453e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9989e-01, 1.0689e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9992e-01, 8.4178e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9924e-01, 7.6442e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 3.3150e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 4.7067e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9927e-01, 7.3495e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9961e-01, 3.9291e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 4.6683e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 6.4382e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9961e-01, 3.9067e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9989, 0.0011]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9987e-01, 1.2524e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 5.2157e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 3.7152e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9998e-01, 2.3241e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9990, 0.0010]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.6378e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 3.9531e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.0035e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9985e-01, 1.5470e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9962e-01, 3.8023e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 6.8585e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.0282e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9991e-01, 8.7672e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 4.9095e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 4.3345e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9997e-01, 2.6357e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9911e-01, 8.9248e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9979, 0.0021]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9981e-01, 1.9034e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9990e-01, 9.8010e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9988e-01, 1.1915e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9999e-01, 1.2328e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9996e-01, 3.7843e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9982e-01, 1.7990e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 4.8504e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9981e-01, 1.8704e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9995e-01, 5.3403e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9993e-01, 6.9562e-05]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9967, 0.0033]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9978e-01, 2.2061e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! If your robot is plugged in it should now be generating new commands with each new camera frame.  Perhaps start by placing your robot on the ground and seeing what it does when it reaches an obstacle.\n",
    "\n",
    "If you want to stop this behavior, you can unattach this callback by executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps you want the robot to run without streaming video to the browser.  You can unlink the camera as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()  # don't stream to browser (will still run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue streaming call the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.link()  # stream to browser (wont run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "That's it for this live demo!  Hopefully you had some fun and your robot avoided collisions intelligently! \n",
    "\n",
    "If your robot wasn't avoiding collisions very well, try to spot where it fails.  The beauty is that we can collect more data for these failure scenarios\n",
    "and the robot should get even better :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
