{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision Avoidance - Live Demo\n",
    "\n",
    "In this notebook we'll use the model we trained to detect whether the robot is ``free`` or ``blocked`` to enable a collision avoidance behavior on the robot.  \n",
    "\n",
    "## Load the trained model\n",
    "\n",
    "We'll assumed that you've already downloaded the ``best_model.pth`` to your workstation as instructed in the training notebook.  Now, you should upload this model into this notebook's\n",
    "directory by using the Jupyter Lab upload tool.  Once that's finished there should be a file named ``best_model.pth`` in this notebook's directory.  \n",
    "\n",
    "> Please make sure the file has uploaded fully before calling the next cell\n",
    "\n",
    "Execute the code below to initialize the PyTorch model.  This should look very familiar from the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the trained weights from the ``best_model.pth`` file that you uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_c_stop.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the model weights are located on the CPU memory execute the code below to transfer to the GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the preprocessing function\n",
    "\n",
    "We have now loaded our model, but there's a slight issue.  The format that we trained our model doesnt *exactly* match the format of the camera.  To do that, \n",
    "we need to do some *preprocessing*.  This involves the following steps\n",
    "\n",
    "1. Convert from BGR to RGB\n",
    "2. Convert from HWC layout to CHW layout\n",
    "3. Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "4. Transfer the data from CPU memory to GPU memory\n",
    "5. Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We've now defined our pre-processing function which can convert images from the camera format to the neural network input format.\n",
    "\n",
    "Now, let's start and display our camera.  You should be pretty familiar with this by now.  We'll also create a slider that will display the\n",
    "probability that the robot is blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fe72e503564011960348124e095793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00Câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image, blocked_slider]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create our robot instance which we'll need to drive the motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a function that will get called whenever the camera's value changes.  This function will do the following steps\n",
    "\n",
    "1. Pre-process the camera image\n",
    "2. Execute the neural network\n",
    "3. While the neural network output indicates we're blocked, we'll turn left, otherwise we go forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.8636e-07, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def update(change):\n",
    "    global blocked_slider, robot\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    print(y)\n",
    "    \n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    \n",
    "    blocked_slider.value = prob_blocked\n",
    "    \n",
    "    if prob_blocked < 0.5:\n",
    "        robot.forward(0.4)\n",
    "    else:\n",
    "        robot.stop()\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to intialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We've created our neural network execution function, but now we need to attach it to the camera for processing. \n",
    "\n",
    "We accomplish that with the ``observe`` function.\n",
    "\n",
    "> WARNING: This code will move the robot!! Please make sure your robot has clearance.  The collision avoidance should work, but the neural\n",
    "> network is only as good as the data it's trained on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0885e-05, 9.9996e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0031, 0.9969]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7949e-04, 9.9972e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.2659e-05, 9.9993e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.3216e-05, 9.9997e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.4463e-04, 9.9906e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.0016e-04, 9.9910e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0012, 0.9988]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0044, 0.9956]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.8569e-04, 9.9911e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0470, 0.9530]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0061, 0.9939]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0043, 0.9957]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1489, 0.8511]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0949, 0.9051]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4294, 0.5706]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0212, 0.9788]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3264, 0.6736]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4644, 0.5356]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9251, 0.0749]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3683, 0.6317]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9124, 0.0876]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8313, 0.1687]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6452, 0.3548]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4997, 0.5003]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9895, 0.0105]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8718, 0.1282]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9769, 0.0231]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6425, 0.3575]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9256, 0.0744]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1752, 0.8248]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8868, 0.1132]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9449, 0.0551]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9798, 0.0202]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9897, 0.0103]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.2030, 0.7970]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8421, 0.1579]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8541, 0.1459]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6072, 0.3928]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8560, 0.1440]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.2063, 0.7937]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9202, 0.0798]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7955, 0.2045]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.2333, 0.7667]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9803, 0.0197]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8667, 0.1333]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6896, 0.3104]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7488, 0.2512]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.2764, 0.7236]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9897, 0.0103]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5969, 0.4031]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7345, 0.2655]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9330, 0.0670]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9214, 0.0786]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9837, 0.0163]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8742, 0.1258]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8207, 0.1793]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9886, 0.0114]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9652, 0.0348]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6371, 0.3629]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5764, 0.4236]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9206, 0.0794]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9824, 0.0176]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9317, 0.0683]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8997, 0.1003]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9866, 0.0134]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9788, 0.0212]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9199, 0.0801]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8336, 0.1664]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9313, 0.0687]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6862, 0.3138]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9833, 0.0167]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8595, 0.1405]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8622, 0.1378]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9803, 0.0197]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9673, 0.0327]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9299, 0.0701]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9271, 0.0729]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9233, 0.0767]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9449, 0.0551]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9956, 0.0044]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9838, 0.0162]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9686, 0.0314]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9554, 0.0446]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9494, 0.0506]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7076, 0.2924]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9106, 0.0894]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9138, 0.0862]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9422, 0.0578]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9242, 0.0758]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7156, 0.2844]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9877, 0.0123]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9679, 0.0321]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3592, 0.6408]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9397, 0.0603]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8918, 0.1082]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8467, 0.1533]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9783, 0.0217]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4997, 0.5003]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9300, 0.0700]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9558, 0.0442]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9401, 0.0599]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8909, 0.1091]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9580, 0.0420]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9837, 0.0163]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9868, 0.0132]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9317, 0.0683]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9607, 0.0393]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9923, 0.0077]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9416, 0.0584]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7982, 0.2018]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9858, 0.0142]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9529, 0.0471]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9390, 0.0610]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8973, 0.1027]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8503, 0.1497]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9656, 0.0344]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8441, 0.1559]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6872, 0.3128]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9765, 0.0235]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9966, 0.0034]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9262, 0.0738]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9460, 0.0540]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9385, 0.0615]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8013, 0.1987]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9033, 0.0967]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9542, 0.0458]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8462, 0.1538]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8873, 0.1127]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9883, 0.0117]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6092, 0.3908]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9883, 0.0117]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9548, 0.0452]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9364, 0.0636]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9235, 0.0765]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9842, 0.0158]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9392, 0.0608]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9771, 0.0229]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5486, 0.4514]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9915, 0.0085]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9659, 0.0341]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9147, 0.0853]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9880, 0.0120]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7737, 0.2263]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9768, 0.0232]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5945, 0.4055]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9686, 0.0314]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9494, 0.0506]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9532, 0.0468]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9612, 0.0388]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9883, 0.0117]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7997, 0.2003]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9596, 0.0404]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9728, 0.0272]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9789, 0.0211]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9935, 0.0065]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8584, 0.1416]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9919, 0.0081]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9227, 0.0773]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6102, 0.3898]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9588, 0.0412]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7283, 0.2717]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7945, 0.2055]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6301, 0.3699]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9975, 0.0025]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9560, 0.0440]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9591, 0.0409]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9928, 0.0072]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9517, 0.0483]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9916, 0.0084]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9768, 0.0232]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9537, 0.0463]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9915, 0.0085]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9118, 0.0882]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9155, 0.0845]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8818, 0.1182]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9785, 0.0215]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8348, 0.1652]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9723, 0.0277]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9636, 0.0364]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9797, 0.0203]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9887, 0.0113]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9854, 0.0146]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5300, 0.4700]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9975, 0.0025]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9905, 0.0095]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9813, 0.0187]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9929, 0.0071]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9361, 0.0639]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9882, 0.0118]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9513, 0.0487]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9930, 0.0070]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9969, 0.0031]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9792, 0.0208]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9221, 0.0779]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9939, 0.0061]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8719, 0.1281]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9884, 0.0116]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9347, 0.0653]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7699, 0.2301]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8966, 0.1034]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.2934, 0.7066]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9770, 0.0230]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8931, 0.1069]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6059, 0.3941]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9971, 0.0029]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9562, 0.0438]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9705, 0.0295]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9580, 0.0420]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9755, 0.0245]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9936, 0.0064]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9936, 0.0064]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9846, 0.0154]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9961, 0.0039]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9706, 0.0294]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9805, 0.0195]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9895, 0.0105]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8618, 0.1382]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9445, 0.0555]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9596, 0.0404]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9132, 0.0868]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9957, 0.0043]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7086, 0.2914]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8038, 0.1962]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9703, 0.0297]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9856, 0.0144]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9709, 0.0291]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8645, 0.1355]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9922, 0.0078]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9823, 0.0177]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9637, 0.0363]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9686, 0.0314]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8422, 0.1578]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8780, 0.1220]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9867, 0.0133]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9846, 0.0154]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9931, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8172, 0.1828]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9320, 0.0680]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9960, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9781, 0.0219]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9255, 0.0745]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9893, 0.0107]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8805, 0.1195]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9819, 0.0181]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7770, 0.2230]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9641, 0.0359]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8241, 0.1759]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7173, 0.2827]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9814, 0.0186]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9918, 0.0082]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9784, 0.0216]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9012, 0.0988]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8437, 0.1563]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9603, 0.0397]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9570, 0.0430]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9182, 0.0818]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9407, 0.0593]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9875, 0.0125]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8759, 0.1241]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9833, 0.0167]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9251, 0.0749]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7544, 0.2456]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8080, 0.1920]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9917, 0.0083]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9456, 0.0544]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9931, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9876, 0.0124]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9624, 0.0376]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8899, 0.1101]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9707, 0.0293]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8973, 0.1027]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9342, 0.0658]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9610, 0.0390]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8417, 0.1583]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9544, 0.0456]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9728, 0.0272]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9140, 0.0860]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9611, 0.0389]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9857, 0.0143]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8587, 0.1413]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9440, 0.0560]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9950, 0.0050]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9965, 0.0035]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9080, 0.0920]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9614, 0.0386]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8596, 0.1404]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9837, 0.0163]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9937, 0.0063]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8597, 0.1403]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9716, 0.0284]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6316, 0.3684]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9904, 0.0096]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9658, 0.0342]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9390, 0.0610]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9336, 0.0664]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9434, 0.0566]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9650, 0.0350]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8346, 0.1654]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8431, 0.1569]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9747, 0.0253]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9762, 0.0238]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7893, 0.2107]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9375, 0.0625]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9349, 0.0651]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9723, 0.0277]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9768, 0.0232]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8532, 0.1468]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8945, 0.1055]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9806, 0.0194]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9713, 0.0287]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9487, 0.0513]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9404, 0.0596]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9365, 0.0635]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9187, 0.0813]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9710, 0.0290]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9374, 0.0626]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8963, 0.1037]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8122, 0.1878]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9718, 0.0282]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9595, 0.0405]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9830, 0.0170]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9703, 0.0297]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9259, 0.0741]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9758, 0.0242]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8244, 0.1756]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9779, 0.0221]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9731, 0.0269]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8398, 0.1602]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9895, 0.0105]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9712, 0.0288]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9637, 0.0363]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9977, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9544, 0.0456]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9463, 0.0537]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9441, 0.0559]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9095, 0.0905]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9569, 0.0431]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9816, 0.0184]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9876, 0.0124]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9437, 0.0563]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9397, 0.0603]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9932, 0.0068]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9609, 0.0391]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9823, 0.0177]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9389, 0.0611]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9870, 0.0130]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9653, 0.0347]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9230, 0.0770]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9600, 0.0400]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9740, 0.0260]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9944, 0.0056]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7030, 0.2970]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9723, 0.0277]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8803, 0.1197]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7236, 0.2764]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8688, 0.1312]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9770, 0.0230]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9721, 0.0279]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9718, 0.0282]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9816, 0.0184]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9842, 0.0158]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9531, 0.0469]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9892, 0.0108]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9457, 0.0543]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9903, 0.0097]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8516, 0.1484]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9808, 0.0192]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9933, 0.0067]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4128, 0.5872]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9554, 0.0446]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9966, 0.0034]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9303, 0.0697]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9819, 0.0181]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9290, 0.0710]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9836, 0.0164]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9313, 0.0687]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9964, 0.0036]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9666, 0.0334]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8817, 0.1183]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9823, 0.0177]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9162, 0.0838]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9715, 0.0285]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9660, 0.0340]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7414, 0.2586]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9758, 0.0242]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9508, 0.0492]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9861, 0.0139]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9225, 0.0775]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9852, 0.0148]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9836, 0.0164]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9939, 0.0061]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9538, 0.0462]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9868, 0.0132]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9775, 0.0225]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9402, 0.0598]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9938, 0.0062]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9944, 0.0056]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9897, 0.0103]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9740, 0.0260]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9600, 0.0400]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9481, 0.0519]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9543, 0.0457]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9115, 0.0885]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9978, 0.0022]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9947, 0.0053]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9980, 0.0020]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8976, 0.1024]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9793, 0.0207]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9929, 0.0071]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8568, 0.1432]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9103, 0.0897]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9958, 0.0042]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9960, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9802, 0.0198]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9890, 0.0110]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9500, 0.0500]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8929, 0.1071]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9904, 0.0096]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9384, 0.0616]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9800, 0.0200]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9822, 0.0178]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8288, 0.1712]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9698, 0.0302]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9907, 0.0093]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9895, 0.0105]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9817, 0.0183]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9363, 0.0637]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9695, 0.0305]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9909, 0.0091]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9784, 0.0216]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8899, 0.1101]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9967, 0.0033]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9834, 0.0166]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9345, 0.0655]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9844, 0.0156]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9858, 0.0142]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9646, 0.0354]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8909, 0.1091]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9913, 0.0087]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9914, 0.0086]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9002, 0.0998]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9633, 0.0367]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9844, 0.0156]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9943, 0.0057]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9941, 0.0059]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9949, 0.0051]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9812, 0.0188]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9949, 0.0051]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7424, 0.2576]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9960, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9967, 0.0033]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9971, 0.0029]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9874, 0.0126]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9790, 0.0210]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9145, 0.0855]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9510, 0.0490]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9554, 0.0446]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9606, 0.0394]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9509, 0.0491]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6870, 0.3130]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9629, 0.0371]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5135, 0.4865]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6884, 0.3116]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7530, 0.2470]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3808, 0.6192]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0152, 0.9848]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2973e-04, 9.9987e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.4422e-04, 9.9976e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0029, 0.9971]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5938e-04, 9.9974e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.5931e-04, 9.9914e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.4006e-05, 9.9994e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.7978e-05, 9.9996e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2533e-04, 9.9987e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.3136e-06, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4034e-04, 9.9986e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1735e-04, 9.9988e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.0208e-05, 9.9995e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9203e-04, 9.9981e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7827e-04, 9.9982e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.6834e-06, 9.9999e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.8411e-04, 9.9972e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.8044e-05, 9.9992e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0027, 0.9973]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5478e-04, 9.9985e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.1619e-04, 9.9948e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0016, 0.9984]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.7518e-05, 9.9990e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.9827e-05, 9.9993e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0019, 0.9981]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0176, 0.9824]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0088, 0.9912]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.4182e-04, 9.9916e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0194, 0.9806]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0106, 0.9894]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0142, 0.9858]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0240, 0.9760]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0438, 0.9562]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0066, 0.9934]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0076, 0.9924]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.0167e-04, 9.9970e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0013, 0.9987]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0105, 0.9895]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0094, 0.9906]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0592, 0.9408]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.2025, 0.7975]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1048, 0.8952]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1274, 0.8726]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1128, 0.8872]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0655, 0.9345]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0152, 0.9848]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1039, 0.8961]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0140, 0.9860]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0085, 0.9915]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.2017, 0.7983]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0626, 0.9374]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0883, 0.9117]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0456, 0.9544]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0941, 0.9059]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0019, 0.9981]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0725, 0.9275]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0276, 0.9724]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0141, 0.9859]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0442, 0.9558]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0607, 0.9393]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0515, 0.9485]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0047, 0.9953]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0058, 0.9942]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0143, 0.9857]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0241, 0.9759]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0152, 0.9848]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0085, 0.9915]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.3882e-04, 9.9926e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0088, 0.9912]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0048, 0.9952]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0036, 0.9964]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.7668e-04, 9.9952e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0028, 0.9972]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0106, 0.9894]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0027, 0.9973]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.4024e-04, 9.9946e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0093, 0.9907]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0019, 0.9981]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0089, 0.9911]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0052, 0.9948]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0028, 0.9972]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0048, 0.9952]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0059, 0.9941]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0188, 0.9812]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0309, 0.9691]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0182, 0.9818]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.9894e-04, 9.9920e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0202, 0.9798]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0137, 0.9863]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0054, 0.9946]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0162, 0.9838]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0077, 0.9923]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0080, 0.9920]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0061, 0.9939]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0017, 0.9983]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.4990e-04, 9.9905e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.4205e-04, 9.9916e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0171, 0.9829]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0036, 0.9964]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0110, 0.9890]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0052, 0.9948]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0207, 0.9793]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0042, 0.9958]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0063, 0.9937]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.2101e-04, 9.9968e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0164, 0.9836]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0065, 0.9935]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0015, 0.9985]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0042, 0.9958]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0014, 0.9986]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0034, 0.9966]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0016, 0.9984]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0015, 0.9985]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0034, 0.9966]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0025, 0.9975]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0021, 0.9979]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.5097e-04, 9.9965e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0045, 0.9955]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0413, 0.9587]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0107, 0.9893]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0022, 0.9978]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0092, 0.9908]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0023, 0.9977]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6563e-04, 9.9983e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5211e-04, 9.9975e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.6776e-04, 9.9973e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0262, 0.9738]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0040, 0.9960]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.0672e-04, 9.9949e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0030, 0.9970]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0014, 0.9986]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0127, 0.9873]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0028, 0.9972]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0104, 0.9896]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0026, 0.9974]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0047, 0.9953]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0104, 0.9896]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0025, 0.9975]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0084, 0.9916]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0027, 0.9973]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.6983e-04, 9.9953e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0031, 0.9969]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0108, 0.9892]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.3872e-04, 9.9966e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0021, 0.9979]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0061, 0.9939]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0139, 0.9861]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0015, 0.9985]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0020, 0.9980]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0012, 0.9988]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0026, 0.9974]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0070, 0.9930]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0034, 0.9966]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0028, 0.9972]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0049, 0.9951]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0076, 0.9924]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0025, 0.9975]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0049, 0.9951]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0789, 0.9211]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0012, 0.9988]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0412, 0.9588]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0028, 0.9972]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.3088e-04, 9.9937e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0306, 0.9694]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0020, 0.9980]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0089, 0.9911]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0075, 0.9925]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0060, 0.9940]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0071, 0.9929]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0063, 0.9937]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.6111e-04, 9.9934e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0155, 0.9845]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0186, 0.9814]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0034, 0.9966]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0275, 0.9725]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0045, 0.9955]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0162, 0.9838]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0670, 0.9330]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1877e-04, 9.9968e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0014, 0.9986]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0078, 0.9922]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0016, 0.9984]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0023, 0.9977]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0039, 0.9961]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0012, 0.9988]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0018, 0.9982]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0024, 0.9976]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0390, 0.9610]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0076, 0.9924]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0022, 0.9978]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.7789e-04, 9.9902e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0101, 0.9899]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0167, 0.9833]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! If your robot is plugged in it should now be generating new commands with each new camera frame.  Perhaps start by placing your robot on the ground and seeing what it does when it reaches an obstacle.\n",
    "\n",
    "If you want to stop this behavior, you can unattach this callback by executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps you want the robot to run without streaming video to the browser.  You can unlink the camera as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()  # don't stream to browser (will still run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue streaming call the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.link()  # stream to browser (wont run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "That's it for this live demo!  Hopefully you had some fun and your robot avoided collisions intelligently! \n",
    "\n",
    "If your robot wasn't avoiding collisions very well, try to spot where it fails.  The beauty is that we can collect more data for these failure scenarios\n",
    "and the robot should get even better :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
