{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Following \n",
    "問題2では、問題1と同じ手順で行います！ 画像分類の代わりに、JetBotが道路（または実際には任意のパスまたはターゲットポイント）をたどることができるようにするために使用する、別の基本的な手法である回帰を学習します。\n",
    "\n",
    "JetBotをパス上のさまざまな位置に配置します（中心からのオフセット、さまざまな角度など）\n",
    "衝突回避から覚えておいてください、データのバリエーションが重要です！\n",
    "\n",
    "ロボットからのライブカメラフィードを表示する\n",
    "ゲームパッドコントローラーを使用して、ロボットに移動させたいターゲットの方向に対応する「緑の点」を画像上に配置します。\n",
    "この緑色の点のX、Y値をロボットのカメラからの画像とともに保存します\n",
    "次に、トレーニングノートブックで、ニューラルネットワークをトレーニングして、ラベルのX、Y値を予測します。ライブデモでは、予測されたX、Yの値を使用して、おおよそのステアリング値を計算します（画像のキャリブレーションが必要になるため、「正確に」角度ではありませんが、角度にほぼ比例するため、コントローラーは正常に動作します） ）。\n",
    "\n",
    "それでは、この例のターゲットを正確にどこに配置するのでしょうか？ここに役立つと思われるガイドがあります\n",
    "\n",
    "カメラからのライブビデオフィードを見てください\n",
    "ロボットがたどるべき経路を想像してください（道路からの脱出などを回避するために必要な距離を概算してみてください）\n",
    "ロボットが道路を「走る」ことなくターゲットにまっすぐ進むことができるように、ターゲットをこのパスに沿ってできるだけ遠くに配置します。\n",
    "たとえば、非常にまっすぐな道路を走行している場合、水平線に配置できます。急旋回している場合は、境界の外に出ないようにロボットの近くに配置する必要があります。\n",
    "\n",
    "ディープラーニングモデルが意図したとおりに機能すると仮定すると、これらのラベリングガイドラインでは次のことが保証されます。\n",
    "\n",
    "ロボットは、ターゲットに向かって安全に直接移動できます（範囲外に出ることなく）。\n",
    "目標は私たちの想像した道に沿って絶えず進歩\n",
    "私たちが得るものは、私たちの望む軌道に沿って動く「スティック上のニンジン」です。ディープラーニングがニンジンを配置する場所を決定し、JetBotがそれに従います:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ集めの様子\n",
    "\n",
    "実際のデータ集めの様子を映像で確認してください\n",
    "> コツは様々な角度から道の中央線にポインタを向けて撮影することです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/display.py:689: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FW4En6LejhI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from IPython.display import HTML\n",
    "# HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FW4En6LejhI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリをインポートしています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、「データ収集」のために必要なすべてのライブラリをインポートすることから始めましょう。 主にOpenCVを使用して、ラベル付きの画像を視覚化し保存します。 uuid、datetimeなどのライブラリは、イメージの命名に使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython Libraries for display and widgets\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Camera and Motor Interface for JetBot\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "\n",
    "# Python basic pakcages for image annotation\n",
    "from uuid import uuid1\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Live Camera Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's initialize and display our camera like we did in the teleoperation notebook. \n",
    "\n",
    "We use Camera Class from JetBot to enable CSI MIPI camera. Our neural network takes a 224x224 pixel image as input. We'll set our camera to that size to minimize the filesize of our dataset (we've tested that it works for this task). In some scenarios it may be better to collect data in a larger image size and downscale to the desired size later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435a816891fd4b2e9972692305293be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4e08b4fb5c485ca7d5dbdba2dfa48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32488c20f554968959ff387efe8712b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='y', max=1.0, min=-1.0, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera = Camera()\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "target_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "# 緑色のポインタを移動させるためのバーを表示します\n",
    "# バーは-1.0から1.0まで動かすことができます\n",
    "x_slider = widgets.FloatSlider(min=-1.0, max=1.0, step=0.001, description='x')\n",
    "y_slider = widgets.FloatSlider(min=-1.0, max=1.0, step=0.001, description='y')\n",
    "\n",
    "def display_xy(camera_image):\n",
    "    image = np.copy(camera_image)\n",
    "    \n",
    "    # バーはの値を取得しています\n",
    "    x = x_slider.value\n",
    "    y = y_slider.value\n",
    "    \n",
    "    # 座標が-1.0-1.0で表されているので、それを0-224に変更する\n",
    "    x = int(x * 224 / 2 + 112)\n",
    "    y = int(y * 224 / 2 + 112)\n",
    "    \n",
    "    # カメラからの映像上に緑色のドットや直線を描画する\n",
    "    image = cv2.circle(image, (x, y), 8, (0, 255, 0), 3)\n",
    "    image = cv2.circle(image, (112, 224), 8, (0, 0,255), 3)\n",
    "    image = cv2.line(image, (x,y), (112,224), (255,0,0), 3)\n",
    "    jpeg_image = bgr8_to_jpeg(image)\n",
    "    return jpeg_image\n",
    "\n",
    "time.sleep(1)\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "traitlets.dlink((camera, 'value'), (target_widget, 'value'), transform=display_xy)\n",
    "\n",
    "# 作成したバーを表示する\n",
    "display(widgets.HBox([image_widget, target_widget]), x_slider, y_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追加部分S2\n",
    "\n",
    "それでは、保存用のボタンを作成しましょう。\n",
    "サポートミッションwedgets.ipynbを参考にしよう\n",
    "\n",
    "ボタンサイズは`width='128px', height='64px'`で設定し、ボタンのレイアウト設定は変数名を`save_button`にし`description='add blocked'`を`description='save'`に変更してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボタンのサイズの設定\n",
    "\n",
    "# ボタンのレイアウトの設定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、作成したボタンを表示しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_button' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5806e454ebb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_button\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save_button' is not defined"
     ]
    }
   ],
   "source": [
    "display(widgets.HBox([save_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、データを収集します\n",
    "画像を撮影する上での注意点を述べておきます\n",
    "\n",
    "> ・ロードプレートの中央線に緑色のドットを置いて作成してください（1セル目の動画参照）\n",
    "\n",
    "> ・様々な背景で画像を撮影したほうが精度は高くなります\n",
    "\n",
    "> ・画像は40枚以上撮影してください\n",
    "\n",
    "保存される画像は下記のようにxの座標、yの座標がファイル名になります\n",
    "``xy_<x value>_<y value>_<uuid>.jpg``\n",
    "\n",
    "トレーニングするときは、画像をロードし、ファイル名からx、y値を解析します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追加部分S2\n",
    "\n",
    "それでは、撮影した画像を保存するディレクトリを作成していきましょう。\n",
    "mission1でも使ったディレクトリの作成を参考にしてください。\n",
    "\n",
    "ディレクトリ`dataset_xy`を作成し、変数名を`DATASET_DIR`にして下さい。\n",
    "\n",
    "※今回は`dataset_xy`という名前のディレクトリがあればいいので、`free`,`blocked`ディレクトリは必要ありません。\n",
    "\n",
    "※今回のディレクトリ名は`dataset/dataset_xy`ではなく、直接`dataset_xy`と指定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET_DIRという変数にdataset_xyを代入してください\n",
    "\n",
    "\n",
    "try:\n",
    "    #ディレクトリをプログラムを追加してください\n",
    "    \n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、撮影画像の合計枚数を表示しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_widget = widgets.IntText(description='count', value=len(glob.glob(os.path.join(DATASET_DIR, '*.jpg'))))\n",
    "display(widgets.VBox([\n",
    "    count_widget\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "撮影して保存するメソッドの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_uuid(x, y):\n",
    "    return 'xy_%03d_%03d_%s' % (x * 50 + 50, y * 50 + 50, uuid1())\n",
    "\n",
    "# 画像を保存している\n",
    "def save_snapshot():\n",
    "    uuid = xy_uuid(x_slider.value, y_slider.value)\n",
    "    image_path = os.path.join(DATASET_DIR, uuid + '.jpg')\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(image_widget.value)\n",
    "    count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "\n",
    "# ボタンと撮影するメソッドを紐づける\n",
    "save_button.on_click(lambda x: save_snapshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、撮影画像をzipファイルにしよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestr():\n",
    "    return str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "\n",
    "!zip -r -q road_following_{DATASET_DIR}_{timestr()}.zip {DATASET_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a file named road_following_<Date&Time>.zip in the Jupyter Lab file browser. You should download the zip file using the Jupyter Lab file browser by right clicking and selecting Download."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
